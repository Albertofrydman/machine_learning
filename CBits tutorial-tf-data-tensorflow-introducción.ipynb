{"cells":[{"cell_type":"markdown","metadata":{"id":"gVbt8YaW39yF"},"source":["# `tf.data`: la mejor manera de gestionar datos en TensorFlow\n","\n","Tensorflow es una de las librerías más usadas para la implementación de modelos de Deep Learning, como las redes neuronales, las convolucionales, las lstm o las redes transformer.\n","\n","Y una fase clave en esta implementación es lograr llevar los datos desde la fuente, que puede ser una base de datos o una carpeta de archivos, hasta el modelo para poder realizar su entrenamiento.\n","\n","Así que en este tutorial veremos una introducción al módulo `tf.data` de TensorFlow, el método más recomendado para realizar esta gestión de los datos a través de esta librería.\n","\n","Entonces comenzaremos entendiendo las principales características y ventajas de `tf.data` frente a otras alternativas y luego veremos un ejemplo básico de uso para entender la lógica de funcionamiento de este módulo."]},{"cell_type":"markdown","metadata":{"id":"5OUN3kqREZUP"},"source":["## 1. Creación de un dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZE3RI8S337CD"},"outputs":[],"source":["# Importar TensorFlow\n","import tensorflow as tf"]},{"cell_type":"markdown","metadata":{"id":"rEzUFNAfEqpb"},"source":["En este tutorial introductorio veremos las herramientas básicas que ofrece `tf.data`.\n","\n","Así que usaremos un dataset que consiste en un simple arreglo de números y veremos cómo gestionarlo usando este módulo.\n","\n","En próximos tutoriales veremos formas más avanzadas de usar el módulo usando datos como imágenes, texto o datos tabulares."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9CNPUei99Lwy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733952758166,"user_tz":300,"elapsed":5,"user":{"displayName":"Alberto Frydman","userId":"15645709566698782283"}},"outputId":"ed5ed8c5-faa0-4c5f-fe99-efd52676f55b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>"]},"metadata":{},"execution_count":2}],"source":["# Crear un dataset super-simple\n","x = [23, 72, 17, -2, 45, 1]\n","\n","# Crear el dataset usando el módulo \"Dataset\" de \"tf.data\"\n","dataset = tf.data.Dataset.from_tensor_slices(x)\n","dataset"]},{"cell_type":"markdown","metadata":{"id":"UBRfJ8EVFKJG"},"source":["Cada dato del set de datos original es almacenado en un Tensor (un tipo de dato de TensorFlow que es en esencia un arreglo).\n","\n","Para ver el contenido de este set de datos podemos iterar sobre cada elemento:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s_vs6Jdw9ik7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733952774017,"user_tz":300,"elapsed":323,"user":{"displayName":"Alberto Frydman","userId":"15645709566698782283"}},"outputId":"f9e8feed-40eb-45e0-9c12-6e911017724f"},"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(23, shape=(), dtype=int32)\n","tf.Tensor(72, shape=(), dtype=int32)\n","tf.Tensor(17, shape=(), dtype=int32)\n","tf.Tensor(-2, shape=(), dtype=int32)\n","tf.Tensor(45, shape=(), dtype=int32)\n","tf.Tensor(1, shape=(), dtype=int32)\n"]}],"source":["# ¿Cómo ver el contenido?\n","for dato in dataset:\n","    print(dato)"]},{"cell_type":"code","source":["dataset"],"metadata":{"id":"pixEzZWrqSMs","executionInfo":{"status":"ok","timestamp":1733953279112,"user_tz":300,"elapsed":5,"user":{"displayName":"Alberto Frydman","userId":"15645709566698782283"}},"outputId":"eb2e7338-64a5-432b-e0a9-d707f8c6a554","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>"]},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"ZW39tC9aFXew"},"source":["Y lo anterior nos permite verificar los detalles de cada uno de los tensores que conforman el dataset.\n","\n","Podemos representar cada dato en formato NumPy para entender fácilmente su contenido:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_1z6pwNH9ms8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733952791256,"user_tz":300,"elapsed":311,"user":{"displayName":"Alberto Frydman","userId":"15645709566698782283"}},"outputId":"1f11aa87-3e57-49c5-9ac3-b0fb23635623"},"outputs":[{"output_type":"stream","name":"stdout","text":["23\n","72\n","17\n","-2\n","45\n","1\n"]}],"source":["# ¿Y si quiero cada dato en formato NumPy?\n","for dato in dataset:\n","    print(dato.numpy())"]},{"cell_type":"markdown","metadata":{"id":"FETyEVRXFgGl"},"source":["## 2. Técnicas básicas para manipular el dataset\n","\n","Una primera técnica es tomar algunos elementos del dataset.\n","\n","Para ello usamos el método `take` que permite tomar los \"n\" primeros elementos (donde \"n\" es el argumento de este método):"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DZi-3Kxm-JoC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733952818673,"user_tz":300,"elapsed":279,"user":{"displayName":"Alberto Frydman","userId":"15645709566698782283"}},"outputId":"3ffb56e3-607f-409e-92f2-05efd8d287ae"},"outputs":[{"output_type":"stream","name":"stdout","text":["23\n","72\n","17\n"]}],"source":["# Tomar algunos elementos: take\n","\n","# Los 3 primeros\n","for dato in dataset.take(3):\n","    print(dato.numpy())"]},{"cell_type":"markdown","metadata":{"id":"gQUYZh2QFwxj"},"source":["Otra técnica muy usada es la transformación de los datos: modificar sus valores para que resulten adecuados al momento de llevarlos al modelo.\n","\n","En este caso particular supongamos que no nos interesa presentar al modelo los valores negativos.\n","\n","Entonces podemos usar el método `filter` combinado con una función `lambda` de Python para filtrar los elementos no deseados:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4iDEJGs6-jN3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733952837902,"user_tz":300,"elapsed":302,"user":{"displayName":"Alberto Frydman","userId":"15645709566698782283"}},"outputId":"b90c3613-259b-43de-957e-ac916867c217"},"outputs":[{"output_type":"stream","name":"stdout","text":["23\n","72\n","17\n","45\n","1\n"]}],"source":["# Ejemplo de transformación: filtrar los valores negativos\n","\n","dataset_filtrado = dataset.filter(lambda y: y>0)\n","\n","for dato in dataset_filtrado:\n","    print(dato.numpy())"]},{"cell_type":"markdown","metadata":{"id":"gD_6tFlfGICB"},"source":["O por ejemplo, supongamos que nos interesa escalar los valores por un factor de 10.\n","\n","En este caso podemos usar `map` + `lambda`:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"soNrqOmh-9RX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699550745604,"user_tz":300,"elapsed":243,"user":{"displayName":"Miguel Sotaquirá","userId":"16233284746872182672"}},"outputId":"4fcb1011-4683-450a-90b0-e15914001cad"},"outputs":[{"output_type":"stream","name":"stdout","text":["2.3\n","7.2\n","1.7\n","-0.2\n","4.5\n","0.1\n"]},{"output_type":"execute_result","data":{"text/plain":["<_MapDataset element_spec=TensorSpec(shape=(), dtype=tf.float64, name=None)>"]},"metadata":{},"execution_count":8}],"source":["# Dividir cada valor entre 10 y convertir a float\n","dataset_mapeado = dataset.map(lambda y: y/10)\n","\n","for dato in dataset_mapeado:\n","    print(dato.numpy())\n","\n","dataset_mapeado"]},{"cell_type":"markdown","metadata":{"id":"CrgqS2amGRWj"},"source":["Y otra herramienta que **siempre** tendremos que usar será la mezcla aleatoria de los datos.\n","\n","Esta transformación se logra con el método `shuffle`:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xsg2GjxD_Pak","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733953365647,"user_tz":300,"elapsed":297,"user":{"displayName":"Alberto Frydman","userId":"15645709566698782283"}},"outputId":"674a58bf-d90e-438c-f587-0f69e17153cc"},"outputs":[{"output_type":"stream","name":"stdout","text":["23 23\n","72 72\n","17 17\n","-2 -2\n","45 45\n","1 1\n"]}],"source":["# Mezclar los datos\n","dataset_mezclado = dataset.shuffle(1)\n","\n","# Imprimir el dato original y el dato después de la mezcla\n","for dato, dato_s in zip(dataset,dataset_mezclado):\n","    print(dato.numpy(), dato_s.numpy())"]},{"cell_type":"markdown","metadata":{"id":"i-Js3WC9Gr3c"},"source":["En el caso anterior hemos usado un argumento igual a 1 en la función `shuffle`.\n","\n","Este argumento indica la cantidad de elementos que `shuffle` almacenará en memoria al momento de hacer la mezcla aleatoria. **Esto se hace para permitir que podamos mezclar aleatoriamente sets de datos gigantescos, que tienen un tamaño mayor al de la memoria disponible**.\n","\n","Entonces, en cada iteración `shuffle` tomará ese número de elementos, lo mezclará aleatoriamente y repetirá el proceso hasta agotar todos los elementos.\n","\n","Por eso, con un argumento igual a 1 obtendremos exactamente el mismo arreglo original.\n","\n","Y entre más alto sea el valor del argumento más aleatoria será la mezcla.\n","\n","Como en nuestro caso tenemos tan sólo 6 elementos podemos tomarlos todos al momento de hacer la mezcla con `shuffle`:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v41gNOLw_6dk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699550962558,"user_tz":300,"elapsed":5,"user":{"displayName":"Miguel Sotaquirá","userId":"16233284746872182672"}},"outputId":"f517f4dd-594c-485b-d116-63dd1ec542f5"},"outputs":[{"output_type":"stream","name":"stdout","text":["23 72\n","72 17\n","17 -2\n","-2 45\n","45 1\n","1 23\n"]}],"source":["# Mezclar los datos\n","dataset_mezclado = dataset.shuffle(6)\n","\n","# E imprimir el dato original y el dato mezclado\n","for dato, dato_s in zip(dataset,dataset_mezclado):\n","    print(dato.numpy(), dato_s.numpy())"]},{"cell_type":"markdown","metadata":{"id":"xPbHJ6bYHoOL"},"source":["Y como lo vimos en otro tutorial, para asegurar la reproducibilidad del entrenamiento tenemos que fijar la semilla del generador aleatorio.\n","\n","En este caso la semilla permitirá obtener siempre la misma mezcla independientemente de cuando ejecutemos el código.\n","\n","Esta semilla la fijamos con el argumento `seed`:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l4oCvx5gBEtL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733953035106,"user_tz":300,"elapsed":294,"user":{"displayName":"Alberto Frydman","userId":"15645709566698782283"}},"outputId":"f8d7c182-1fbb-457a-f3ac-57743c985205"},"outputs":[{"output_type":"stream","name":"stdout","text":["23 17\n","72 -2\n","17 45\n","-2 1\n","45 23\n","1 72\n"]}],"source":["# Mezclar dataset con una semilla\n","dataset_mezclado = dataset.shuffle(6, seed=31)\n","\n","# Imprimir datos originales y mezclados\n","for dato, dato_s in zip(dataset,dataset_mezclado):\n","    print(dato.numpy(), dato_s.numpy())"]},{"cell_type":"markdown","metadata":{"id":"IcvAYLQjH2qc"},"source":["Otra técnica que siempre tendremos que usar es la generación de lotes.\n","\n","Cuando tenemos un dataset muy grande no podemos leer todos los datos en la RAM, así que tendremos que tomar bloques de datos: los lotes.\n","\n","En este caso podemos usar `batch` que toma bloques de tamaño \"n\" en orden consecutivo.\n","\n","Por ejemplo, creemos lotes de 4 elementos a partir del dataset original:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3y0BMVR1AbT9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699551163482,"user_tz":300,"elapsed":4,"user":{"displayName":"Miguel Sotaquirá","userId":"16233284746872182672"}},"outputId":"9f203397-3c49-43c8-bbf3-dc1b5f68f395"},"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor([23 72 17 -2], shape=(4,), dtype=int32)\n","tf.Tensor([45  1], shape=(2,), dtype=int32)\n"]}],"source":["# Crear batches\n","dataset_batches = dataset.batch(4) # Crear lotes con 4 elementos c/u\n","\n","# Imprimirlos en pantalla\n","for batch in dataset_batches:\n","    print(batch)"]},{"cell_type":"markdown","metadata":{"id":"vEEbnJKRIMWi"},"source":["Y finalmente otra de las operaciones que comúnmente tendremos que realizar es la partición del dataset en entrenamiento, validación y prueba.\n","\n","Comencemos creando un set de datos con que será un simple arreglo de 10 elementos: los números del 1 al 10:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0Gxwv4IlAo2W","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733953498713,"user_tz":300,"elapsed":290,"user":{"displayName":"Alberto Frydman","userId":"15645709566698782283"}},"outputId":"52177134-562c-4c7e-b587-b4316b3de437"},"outputs":[{"output_type":"stream","name":"stdout","text":["1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","10\n"]}],"source":["# 1. Crear el set de datos\n","ds = tf.data.Dataset.from_tensor_slices(range(1,11))\n","\n","for dato in ds:\n","    print(dato.numpy())"]},{"cell_type":"markdown","metadata":{"id":"UYms1pbfIaYo"},"source":["Ahora supongamos que queremos partirlo en 60% para entrenamiento (6 datos), 20% para validación (2 datos) y 20% para prueba (también 2 datos).\n","\n","Comencemos calculando estos tamaños de forma automática:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XV3LTQqrCidD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733953512341,"user_tz":300,"elapsed":275,"user":{"displayName":"Alberto Frydman","userId":"15645709566698782283"}},"outputId":"b1e87a6e-fb6a-46b8-8597-68988747fee3"},"outputs":[{"output_type":"stream","name":"stdout","text":["10 6 2 2\n"]}],"source":["N = len(ds) # Cantidad total de datos (10)\n","tr_size = int(0.6*N)\n","ts_size = int(0.2*N)\n","vl_size = N - tr_size - ts_size # Para que no se pierdan datos por el redondeo\n","\n","print(N, tr_size, ts_size, vl_size)"]},{"cell_type":"markdown","metadata":{"id":"SlM-q2RBIpSd"},"source":["Antes de hacer la partición tenemos que mezclar los datos aleatoriamente usando `shuffle`.\n","\n","Acá es clave que cada vez que hagamos un llamado al dataset mezclado no se mezcle nuevamente. Esto lo hacemos fijando el argumento `reshuffle_each_iteration` como `False`:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K6VTVOPdDHQL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733953612143,"user_tz":300,"elapsed":327,"user":{"displayName":"Alberto Frydman","userId":"15645709566698782283"}},"outputId":"a1850851-5605-46ff-943a-d47c49f75247"},"outputs":[{"output_type":"stream","name":"stdout","text":["1\n","6\n","4\n","3\n","5\n","2\n","7\n","8\n","9\n","10\n"]}],"source":["# Mezclar el dataset y desactivar opción \"reshuffle_each_iteration\"\n","SEED = 423\n","ds = ds.shuffle(N, seed=SEED, reshuffle_each_iteration=False)\n","for dato in ds:\n","    print(dato.numpy())"]},{"cell_type":"markdown","metadata":{"id":"hc16f4P-JBHd"},"source":["Y por último, creamos los sets de entrenamiento, validación y prueba usando los métodos `take` (tomar los primeros \"n\" elementos del dataset) y `skip` (tomar un dataset pero \"saltarse\" los primeros \"n\" elementos:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"snmVhBS-I8Uf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699551525021,"user_tz":300,"elapsed":219,"user":{"displayName":"Miguel Sotaquirá","userId":"16233284746872182672"}},"outputId":"aa52159c-2bff-4ef4-cda9-62e2c5b5c2ef"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train:\n","7\n","3\n","6\n","2\n","1\n","4\n","Test:\n","5\n","10\n","Val:\n","8\n","9\n"]}],"source":["# Entrenamiento: tomar los primeros \"tr_size\" elementos del dataset mezclado\n","ds_train = ds.take(tr_size)\n","\n","# Prueba: \"saltar\" los primeros \"tr_size\" elementos (con \"skip\") y\n","# luego tomar los \"ts_size\" elementos restantes (con \"take\")\n","ds_test = ds.skip(tr_size).take(ts_size)\n","\n","# Validación: \"saltar\" los primeros \"tr_size+ts_size\" elementos (con \"skip\") y\n","# tomar el resto\n","ds_val = ds.skip(tr_size + ts_size)\n","\n","# Imprimir datasets\n","print('Train:')\n","for dato in ds_train:\n","    print(dato.numpy())\n","print('Test:')\n","for dato in ds_test:\n","    print(dato.numpy())\n","print('Val:')\n","for dato in ds_val:\n","    print(dato.numpy())"]},{"cell_type":"markdown","metadata":{"id":"At33ewbnJvxZ"},"source":["¡Y listo, estas son las herramientas básicas que debemos tener en cuenta al momento de usar `tf.data`!\n","\n","## Conclusión\n","\n","Acabamos de ver los principios básicos de funcionamiento del módulo `tf.data` de TensorFlow y en particular de la clase `Dataset` que permiten gestionar los datos al momento de alimentar un modelo de Deep Learning.\n","\n","Y esta gestión tiene básicamente tres fases: la extracción, transformación y carga de los datos. Y precisamente el módulo `tf.data` nos permite implementar fácilmente todas estas fases independientemente del tipo de datos que tengamos (si son tablas, si son imágenes, audios, texto, etc.).\n","\n","Así que el uso de `tf.data` es la forma más adecuada de gestionar los datos cuando estamos implementando modelos en TensorFlow y en próximos tutoriales veremos de forma detallada como manipular diferentes tipos de datos usando precisamente este módulo."]}],"metadata":{"colab":{"provenance":[{"file_id":"1dUvL1J6kQjvoJAzvXwjFvxRhNV5MzcdA","timestamp":1733953697268}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}