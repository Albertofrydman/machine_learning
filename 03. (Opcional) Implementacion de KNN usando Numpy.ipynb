{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1W8Obh6OTaFo6To7nYRKe1zYm6O28upll","timestamp":1723356374446},{"file_id":"1XhcQg131ZMPuLUOtosURrEa9HLWdyW0Q","timestamp":1590895626844},{"file_id":"1t4GuIskA8HUflkaa2KcA0CNzcO8FyxD7","timestamp":1590883788832},{"file_id":"1mXt2QTwHeQ5Q-y_jm_CkyLPrciN7EWWx","timestamp":1590724970854}]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"c2i1T6Sa2-sp"},"source":["# Implementacion de K-Nearest Neighbors (KNN) usando Numpy\n","-----"]},{"cell_type":"markdown","metadata":{"id":"DJw_f5l7xwQl"},"source":["## Importación de Librerías\n","\n","Empecemos importando las librerías. Las librerías principales que usaremos serán `numpy` y `matplotlib`."]},{"cell_type":"code","metadata":{"id":"eZQIIKajxtwe"},"source":["# Operaciones matriciales\n","import numpy as np\n","# Visualización\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l9aO2BN3iiCb"},"source":["## Generación de Datos\n","\n","Antes de iniciar con la implementación generaremos datos en $2$ dimensiones para poder visualizarlos y probar la implementación. Denotaremos a la data como $X$ y las clases o etiquetas como $y$."]},{"cell_type":"code","metadata":{"id":"5l2OFW2QYHdl"},"source":["# Crear mapas de color para visualización\n","from matplotlib.colors import ListedColormap\n","cmap_light = ListedColormap(['#AAAAFF', '#FFAAAA'])\n","cmap_bold = ListedColormap(['#0000FF', '#FF0000'])\n","\n","# Generamos data aleatoria\n","from sklearn.datasets import make_blobs\n","X, y = make_blobs(200, 2, centers=2, random_state=1, cluster_std = 2)\n","\n","# Visualizamos la data generada\n","plt.figure(figsize=(7,6))\n","plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap=cmap_bold)\n","plt.show()\n","\n","print(f'\\nTamaño del conjunto de datos {X.shape}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pf0Y7pMpZNfM"},"source":["Como podemos observar, hemos generado datos simples cuya separabilidad no es muy complicada. Usaremos esta data solamente para fines de probar la implementación. Más adelante generaremos data más compleja."]},{"cell_type":"markdown","metadata":{"id":"BSdAN3MabRiB"},"source":["## Particionamiento de datos\n","\n","Como no contamos con un conjunto de datos de validación y de prueba, el primer paso es particionar los datos.\n","\n","### Particionamiento Hold-out\n","\n","Particionamos nuestro conjunto de datos en entrenamiento y prueba. Para ello, adicionaremos un parámetro `train_size` con valores entre $0$ y $1$ que indica el porcentaje de datos a considerar en la data de entrenamiento. Por ejemplo, si tenemos $200$ datos y especificamos `train_size` igual a $0.8$. Entonces el método retornará dos conjuntos de datos: $(X_{train}, y_{train})$ y $(X_{test}, y_{test})$ con $160$ y $40$ muestras respectivamente.\n"]},{"cell_type":"code","metadata":{"id":"O07aIlmRbozH"},"source":["def train_test_split(X, y, train_size=0.8, random_state=1):\n","  '''\n","    Este método permite dividir un conjunto de datos (X,y) en dos conjuntos\n","    de datos (X_train, y_train) y (X_test, y_test) dada la proporción de datos\n","    de entrenamiento deseado.\n","\n","    Es recomendable aleatorizar los datos antes de realizar la división.\n","\n","    Args:\n","      - X: dataset de dimensión (N x D), donde N es el número de muestras y\n","           D es el número de características.\n","      - y: arreglo de dimensión (N), donde N es el número de muestras. Este\n","           arreglo contiene las etiquetas (clases) de la data.\n","      - train_size: representa la proporción del conjunto de datos a incluir en\n","                    la data de entrenamiento.\n","      - random_state: controla la aleatoriedad aplicada a los datos antes de\n","                      aplicar la división.\n","\n","    Returns:\n","      - X_train: matriz de dimensión (N1 x D)\n","      - y_train: arreglo de dimensión (N1)\n","      - X_test: matriz de dimensión (N2 x D)\n","      - y_test: arreglo de dimensióm (N2)\n","\n","    Note:\n","      - Los datos particionados deben sumar el total (N1+N2 = N)\n","      - Implementar el método usando solo numpy, está permitido usar np.random.\n","      - A continuación se deja una plantilla que puede usar, pero no es\n","        obligatorio, pueden realizar la implementación como mejor le parezca.\n","  '''\n","  N = X.shape[0]\n","\n","  # Usado para controlar la aleatoriedad del particionamiento\n","  np.random.seed(random_state)\n","\n","  # TODO: Realice el particionamiento del conjunto de datos, puede usar la\n","  # plantilla dada a continuación\n","\n","  # Recomendado usar np.random.permutation para aleatorizar los índices de los datos.\n","  indices =\n","\n","  # Definir el número de muestras de la data de entrenamiento\n","  N1 =\n","\n","  # Seleccionar los índices que se usarán en la data de entrenamiento y de prueba\n","  train_indices, test_indices =\n","\n","  # Particionar la data usando los índices seleccionados anteriormente\n","  X_train, y_train =\n","  X_test, y_test =\n","\n","  # Retornamos los conjuntos de datos particionados\n","  return X_train, y_train, X_test, y_test"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cDun2WPEiz09"},"source":["Probemos la implementación del particionamiento:"]},{"cell_type":"code","metadata":{"id":"o6TF_blgj9XV"},"source":["# Test para probar la implementación del particionamiento de datos\n","train_sizes = np.array([0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.75, 0.8, 0.85, 0.9])\n","correct = True\n","for train_size in train_sizes:\n","  _X_train, _y_train, _X_test, _y_test = train_test_split(X, y, train_size)\n","  difference = X.shape[0] - _X_train.shape[0] - _X_test.shape[0]\n","  difference_y = y.shape[0] - _y_train.shape[0] - _y_test.shape[0]\n","  if difference != 0 or difference_y != 0:\n","    print(':( El particionamiento no fue realizado correctamente.\\n')\n","    print(f'Total: ({X.shape},{y.shape})')\n","    print(f'Train: ({_X_train.shape},{_y_train.shape})')\n","    print(f'Test: ({_X_test.shape},{_y_test.shape})')\n","    correct = False\n","    break\n","if correct:\n","  print(':) El particionamiento fue realizado correctamente.')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F5iVONThmdfM"},"source":["Procederemos a particionar el conjunto de datos en entrenamiento, validación y prueba. Para este ejemplo consideraremos un particionamiento de $60\\%$ para entrenamiento, $20\\%$ para validación y $20\\%$ para prueba. Para ello es necesario usar el método antes implementado (`train_test_split`) dos veces."]},{"cell_type":"code","metadata":{"id":"bswhbrQ_i7I7"},"source":["# TODO: Particione el conjunto de datos en entrenamiento (train) y prueba (test)\n","#       usando el 80% para entrenamiento y el 20% para prueba\n","_X_train, _y_train, X_test, y_test =\n","\n","print('Tamaño original del dataset: ', X.shape)\n","print('Tamaño de la data de entrenamiento: ', _X_train.shape)\n","print('Tamaño de la data de prueba: ', X_test.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YosAITvJm-FE"},"source":["# TODO: Particione el conjunto de datos de entrenamiento en un nuevo subconjunto\n","#       de entrenamiento y validación usando el 75% para entrenamiento y el 25%\n","#       para validación. Recuerde que luego de realizar el primer partionamiento\n","#       (80%/20%), la proporción deseada del 60% inicial se convierte en 75%\n","#       en el nuevo dataset.\n","X_train, y_train, X_val, y_val =\n","\n","print('Tamaño original de la data de entrenamiento: ', _X_train.shape)\n","print('Tamaño de la nueva data de entrenamiento: ', X_train.shape)\n","print('Tamaño de la data de validación: ', X_val.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8FFW-Zsdo_cc"},"source":["Para validar sus particionamientos pueden calcular los porcentajes de modo manual y verificar que efectivamente esten obteniendo el $60\\%$ para entrenamiento, $20\\%$ para validación y $20\\%$ para prueba. Procederemos a imprimir los particionamientos de los datasets finales:"]},{"cell_type":"code","metadata":{"id":"1jLOCDg1qbDP"},"source":["print('Tamaño original del dataset: ', X.shape)\n","print('---------------------------')\n","print('Tamaño de la data de entrenamiento: ', X_train.shape)\n","print('Tamaño de la data de validación: ', X_val.shape)\n","print('Tamaño de la data de prueba: ', X_test.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FWqeb_LarolI"},"source":["Recordemos que en cualquier problema de Machine Learning que tengamos, no debemos usar la data de prueba sino hasta después de haber realizado todas nuestras validaciones y elegido todos nuestros hiperparámetros. La data de prueba simula la data que nunca llegamos a ver."]},{"cell_type":"markdown","metadata":{"id":"zruV75f9sF3n"},"source":["## Visualización del dataset\n","\n","Procederemos con la visualización de los particionamientos previamente realizados. En este paso solo mostraremos la data de entrenamiento y de validación para saber el tipo de clasificación que necesitamos realizar. La data de test solo la tocaremos al final de este trabajo."]},{"cell_type":"code","metadata":{"id":"4P0F4FP_uLWi"},"source":["def plot_dataset(X_train, y_train, X_test, y_test, is_validation=True):\n","  \"\"\"\n","     Este método permite visualizar nuestros datos de entrenamiento y prueba\n","  \"\"\"\n","  plt.subplots(figsize =(15, 5))\n","  plt.subplot(1, 2, 1)\n","  plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, s=30, cmap=cmap_bold)\n","  plt.title('Data de Entrenamiento')\n","  plt.subplot(1, 2, 2)\n","  plt.scatter(X_test[:,0], X_test[:,1])\n","  if is_validation:\n","    plt.title('Data de Validación')\n","  else:\n","    plt.title('Data de Prueba')\n","  plt.show()\n","\n","plot_dataset(X_train, y_train, X_val, y_val)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6o0zA2RWqkzp"},"source":["La visualización nos muestra la distribución de ambos conjuntos de datos. Un punto importante a considerar es en los ejes de coordenadas, podemos ver que el eje $x$ tiene un rango de valores distinto al del eje $y$. Recordemos que en general, es muy común que los rangos de valores de diferentes características sea distinto por lo tanto tendremos que estandarizarlos."]},{"cell_type":"markdown","metadata":{"id":"BDeQSXbqkckd"},"source":["## Estandarización del conjunto de datos\n","\n","La estandarización (o **z-score**) es una técnica importante que se realiza principalmente como un paso de preprocesamiento antes de ingresar la data a un modelo de Machine Learning. Un problema muy frecuente en los conjuntos de datos es que muchas de sus características tienen grandes diferencias entre sus rangos (edad, salario, etc.) o simplemente se miden en diferentes unidades de medida (metros, millas, etc). Estas diferencias en los rangos causan problemas a muchos modelos de Machine Learning. Por ejemplo, para los modelos que se basan en el cálculo de la distancia, si una de las características tiene un amplio rango de valores, la distancia se regirá por esta característica en particular.\n","\n","En este taller implementaremos el modelo de los k vecinos más cercanos; como lo visto en clase, este modelo está basado en el cálculo de distancias, por lo tanto será necesario estandarizar los datos antes de ejecutarlo. Para ello, estandarizaremos la data para que la distribución de cada característica tenga una media igual a cero y una desviación estándar igual uno (varianza unitaria), la formulación esta dada por lo siguiente:\n","\n","$$X_{new} = \\frac{X - \\mu}{ \\sigma }$$\n","\n","donde $X_{new}$ es la data estandarizada, $X$ es la data sin estandarizar (data original) y $\\mu$ y $\\sigma$ son la media y desviación estándar de cada característica respectivamente. Recordar que estos valores los calculamos a partir de la data de entrenamiento y los usaremos en la data de validación y prueba. No olvidarse que estás estadísticas se calculan para cada característica (columna) de la data."]},{"cell_type":"code","metadata":{"id":"uwgjKZ3Jpz_t"},"source":["def standardize(X):\n","  \"\"\"Estandarizar el dataset X -> (X - mean) / std\n","\n","    Args:\n","      - X: dataset de dimensión (N x D), donde N es el número de muestras y\n","          D es el número de características.\n","\n","    Returns:\n","      - (X_new, mu, std): X_new es la data estandarizada con media 0 y desviación\n","                          estándar 1; mu y std son la media y desviación estándar\n","                          respectivamente.\n","\n","    Note:\n","      - Es probable que encuentren dimensiones donde la desviación estándar es 0,\n","        y ello implica una división por cero (NaN). Para manejar ese escenario,\n","        reemplace la desviación estándar de 0 por 1 antes de estandarizar.\n","      - A continuación se deja una plantilla que puede usar, pero no es\n","        obligatorio, puede realizar la implementación como mejor le parezca.\n","  \"\"\"\n","  # TODO: Realice la estandarización del conjunto de datos, puede usar la\n","  # plantilla dada a continuación\n","\n","  # Calcular la media y desviación estandar\n","  mu =\n","  std =\n","\n","  # Reemplazar los valores de std=0 con 1\n","  std_filled =\n","\n","  # Estandarizar la data\n","  X_new  =\n","\n","  # Retornamos la data estandarizada y las estadísticas calculadas\n","  return X_new, mu, std_filled"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JipHYlVus6vG"},"source":["Probemos la implementación de la estandarización:"]},{"cell_type":"code","metadata":{"id":"gU6AkIRjs_4S"},"source":["# Test para probar la implementación del particionamiento de datos\n","# recordar que la data estandarizada debe tener una media igual a 0 y desviación\n","# estándar igual a 1 para cada característica\n","\n","# Usado para controlar la aleatoriedad de los datos generados\n","np.random.seed(0)\n","\n","# Generamos datos aleatorios y verificamos si la media es 0 y si la desviación\n","# estándar es 1\n","sizes = np.array([[10,2], [50, 5], [100, 10],[1000,100], [200, 3]])\n","correct = True\n","for size in sizes:\n","  random_data = np.random.randn(*size).astype(np.float64)\n","  random_data_new, _ ,_ = standardize(random_data)\n","  data_mu = random_data_new.mean(0)\n","  data_std = random_data_new.std(0)\n","  if all(abs(data_mu) > 1e-4) or all(abs(data_std - 1) > 1e-4):\n","    print(':( La estandarización no fue realizada correctamente.')\n","    print(f'La media es: {data_mu} y la desviación estándar es: {data_std}')\n","    correct = False\n","    break\n","if correct:\n","  print(':) La estandarización fue realizada correctamente.')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YppnReHpsLMf"},"source":["Estandarizamos la data de entrenamiento y obtenemos sus estadísticas:"]},{"cell_type":"code","metadata":{"id":"6eKhP-0rsaf4"},"source":["X_train_new, X_train_mu, X_train_std = standardize(X_train)\n","\n","# Imprimimos las estadísticas obtenidas, debido al tipo de dato flotante\n","# es probable que la media no sea exactamente 0 pero cercano a ese valor\n","print(\"Media de la nueva data: \", X_train_new.mean(0))\n","print(\"Desviación Estándar de la nueva data: \", X_train_new.std(0))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1hNYhPlNssPQ"},"source":["Para estandarizar la data de validación usaremos la media y desviación estándar calculados en la data de entrenamiento:"]},{"cell_type":"code","metadata":{"id":"lLrJuWCMwF8X"},"source":["def standardize_test(X_test, X_train_mu, X_train_std):\n","  \"\"\"Estandarizar la data de prueba  X -> (X - mu) / std\n","\n","    Args:\n","      - X_test: dataset de dimensión (M x D), donde M es el número de muestras y\n","                D es el número de características.\n","      - X_train_mu: arreglo de dimensión (D), conteniendo la media de cada\n","                    característica hallada en la data de entrenamiento\n","      - X_train_std: arreglo de dimensión (D), conteniendo la desviación estándar\n","                    de cada característica hallada en la data de entrenamiento\n","\n","    Returns:\n","      - X_test_new: dataset de dimensión (M x D), donde M es el número de muestras y\n","                    D es el número de características.\n","\n","    Note:\n","      - Como estamos usando estadísticas de la data de entrenamiento, no es necesario\n","        que la media y desviación estándar de la data de prueba sea 0 y 1\n","        respectivamente\n","  \"\"\"\n","  # TODO: Estandarice la data de prueba usando las estadísticas de la data de entrenamiento\n","  X_test_new =\n","  return X_test_new"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uizXTZ032GuQ"},"source":["Procedemos a estandarizar la data de validación. Tener en cuenta que la media y desviación estándar de la nueva data de validación no necesariamente tiene que ser $0$ y $1$ respectivamente, ya que estamos haciendo uso de las estadísticas de la data de entrenamiento:"]},{"cell_type":"code","metadata":{"id":"-hlI-UyY3Mip"},"source":["X_val_new = standardize_test(X_val, X_train_mu, X_train_std)\n","print(\"Media de la nueva data de validación: \", X_val_new.mean(0))\n","print(\"Desviación Estándar de la nueva data de validación: \", X_val_new.std(0))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tCoxSguMOxXl"},"source":["Visualicemos los datos estandarizados:"]},{"cell_type":"code","metadata":{"id":"g39S9Y12O3m0"},"source":["plot_dataset(X_train_new, y_train, X_val_new, y_val)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DcI8oS5y4Aa8"},"source":["Podemos observar que los rangos de valores fueron correctamente estandarizados, ya que no hay cambios demasiado grandes entre los valores de ambas características.\n","\n","Hemos culminado la fase de preprocesamiento, ahora si podemos usar los datos preprocesados en nuestro modelo de Machine Learning."]},{"cell_type":"markdown","metadata":{"id":"debZo0MTPeGb"},"source":["## Implementación del Modelo\n","\n","Ahora que hemos preprocesado nuestros datos, es hora de implementar el clasificador KNN. Podemos dividir el proceso en dos pasos:\n","\n","1. Calcular las distancias entre todos los datos de prueba y todos los datos de entrenamiento.\n","2. Dadas estas distancias, para cada dato de prueba encontrar los $k$ vecinos más cercanos y asignarles su clase (label) basándonos en el voto mayoritario (moda).\n","\n","En este taller, empezaremos con la implementación del cálculo de distancias. Una vez finalizada esa parte, realizaremos la implementación del clasificador usando solamente al vecino más cercano ($k=1$), y luego generalizaremos la implementación para $k$ vecinos."]},{"cell_type":"markdown","metadata":{"id":"Vk93wRlRBuia"},"source":["## Cálculo de Distancias\n","\n","El clasificador del vecino más cercano compara cada dato de prueba con todos los datos de entrenamiento para predecir sus clases (labels). En este taller usaremos la distancia euclidiana (también llamada $L2$) para comparar nuestras datos.\n","\n","  - Distancia euclidiana (L2): $$ d(x, y) = \\sqrt{\\sum\\limits_i (x_i - y_i)^2}$$\n","    \n","\n","**Importante:** en la práctica no se toma en cuenta el cálculo de la raíz cuadrada ya que al comparar dos distancias, $d(i,j) < d(i,j')$, la raiz cuadrada se cancela. Esto se cumple debido a que la raíz cuadrada es una función monotónicamente creciente. Por lo tanto, en la implementación no será necesario hacer uso de la raíz cuadrada.\n","\n","Implementaremos diferentes versiones del cálculo de distancias. La entrada en nuestros métodos serán: la data de entrenamiento y prueba. La salida será una matriz de distancias donde cada posición $(i,j)$ denota la distancia entre i-ésimo dato de prueba y el j-ésimo dato de entrenamiento."]},{"cell_type":"markdown","metadata":{"id":"bfSlERB1A2p8"},"source":["#### Cálculo de distancias: Implementación usando $2$ bucles\n","\n","Comencemos con la primera versión del cálculo de la matriz de distancias entre todos los ejemplos de prueba y entrenamiento. Primero implementaremos una versión del cálculo de distancia, utilizando bucles explícitos sobre los conjuntos de prueba y entrenamiento:\n"]},{"cell_type":"code","metadata":{"id":"Z3ILtmczDBsP"},"source":["def calculate_distances_two_loops(X_train, X_test):\n","  \"\"\"\n","    Este método permite calcular la distancia euclidiana al cuadrado entre cada\n","    elemento del conjunto de prueba y cada elemento del conjunto de entrenamiento.\n","\n","    distancia(x, y) = (x1 - y1)^2 + (x2 - y2)^2 + ... + (xd - yd)^2\n","\n","    Args:\n","      - X_train: matriz de dimensión (N x D), donde N es el número de datos de\n","                 entrenamiento y D es la dimensión o número de características\n","\n","      - X_test: matriz de dimensión (M x D), donde M es el número de datos de\n","                prueba y D es la dimensión o número de características\n","\n","    Returns:\n","      - dists: matriz de dimensión (M, N) donde dists[i,j] es la distancia euclidiana\n","               entre el i-ésimo dato de prueba y el j-ésimo dato de entrenamiento\n","\n","    Note:\n","      - Cuando comparamos dos elementos, no es necesario calcular la raiz\n","        cuadrada de la distancia euclidiana ya que al comparar d(i,j) < d(i,j')\n","        la raiz cuadrada se cancela.\n","      - Implementar el método usando solo numpy, no es válido usar métodos como\n","        np.norm.\n","  \"\"\"\n","  num_test = X_test.shape[0]\n","  num_train = X_train.shape[0]\n","\n","  # Inicializamos nuestra matriz de distancias\n","  dists = np.zeros((num_test, num_train))\n","\n","  # TODO: Usar 2 bucles para calcular las distancias entre un dato de prueba y\n","  # entrenamiento dentro de ambos bucles.\n","  # Calcule la distancia euclidiana al cuadrado entre el i-ésimo dato de prueba\n","  # y el j-ésimo dato de entrenamiento, y almacene el resultado en la posición\n","  # dists[i][j].\n","\n","\n","  # Retornamos las matriz de distancias\n","  return dists"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FIXiIdIXFJJz"},"source":["Ahora probemos la implementación, para ello debemos ingresar como argumentos la data de entrenamiento y validación previamente preprocesadas, es decir, $(X_{train\\_new}, X_{val\\_new})$"]},{"cell_type":"code","metadata":{"id":"GJr6SGy6FU37"},"source":["dists = calculate_distances_two_loops(X_train_new, X_val_new)\n","print('Tamaño de la matriz de distancias: ', dists.shape)\n","\n","# siempre es recomendable evaluar nuestros métodos con diferentes casos de prueba\n","# por ello, pruebe su implementación con diferentes casos de prueba (opcional)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y953x9CF8s50"},"source":["#### Cálculo de distancias: Implementación usando $1$ bucle y vectorización\n","\n","Nuestra implementación del cálculo de distancia anterior es bastante ineficiente ya que utiliza dos bucles anidados sobre los conjuntos de datos de entrenamiento y prueba. ¿Podemos mejorar esa implementación?\n","\n","El proceso de eliminar bucles explícitos de su código se llama **vectorización**. A veces es sencillo vectorizar el código originalmente escrito con bucles; otras veces, la vectorización requiere pensar en el problema de una nueva manera. Usaremos la vectorización para mejorar la velocidad de nuestra función de cálculo de distancia.\n","\n","Como primer paso para vectorizar nuestro cálculo de distancias, complete el siguiente método que usará solo un bucle sobre los datos de prueba."]},{"cell_type":"code","metadata":{"id":"UnCbmrBcHX8C"},"source":["def calculate_distances_one_loop(X_train, X_test):\n","  \"\"\"\n","    Calcular la distancia euclidiana al cuadrado entre cada elemento del\n","    conjunto de prueba y cada elemento del conjunto de entrenamiento.\n","\n","    distancia(x, y) = (x1 - y1)^2 + (x2 - y2)^2 + ... + (xd - yd)^2\n","\n","    Args / Return: Igual que el método calculate_distances_two_loops\n","\n","    Note:\n","      - Solo puede usar un bucle sobre la data de prueba\n","      - Implementar el método usando solo numpy, no es válido usar métodos como\n","        np.norm\n","  \"\"\"\n","  num_test = X_test.shape[0]\n","  num_train = X_train.shape[0]\n","\n","  # Inicializamos nuestra matriz de distancias\n","  dists = np.zeros((num_test, num_train))\n","\n","  # TODO: Usar 1 bucle para calcular la distancia euclidiana entre el\n","  # i-ésimo dato de prueba y toda la data de entrenamiento.\n","  # Almacene el resultado en la posición dists[i][j].\n","\n","\n","  # Retornamos las matriz de distancias\n","  return dists"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jqJQ0iuy9mGf"},"source":["Podemos verificar la correctitud de nuestra implementación de un bucle comparándola con nuestra implementación de dos bucles en algunos datos generados aleatoriamente. Tenga en cuenta que hacemos la comparación con puntos flotantes de 64 bits para una mayor precisión numérica."]},{"cell_type":"code","metadata":{"id":"mjsng7fkCwB7"},"source":["# Test para probar la implementación de cálculo de distancias\n","\n","# Usado para controlar la aleatoriedad de los datos generados\n","np.random.seed(0)\n","\n","# Tamaños de los datos generados aleatoriamente\n","sizes = np.array([[10,2], [50, 5], [100, 10],[100,100], [200, 3]])\n","correct = True\n","\n","for size in sizes:\n","  X_train_rand = np.random.randn(*size).astype(np.float64)\n","  X_val_rand = np.random.randn(*size).astype(np.float64)\n","  # Hay muchas formas de decidir si dos matrices son similares; Una de las más\n","  # simples es la norma de Frobenius. En caso de que no lo haya visto antes,\n","  # la norma de Frobenius de dos matrices es la raíz cuadrada de la suma cuadrada\n","  # de las diferencias de todos los elementos; en otras palabras, convertir las\n","  # matrices en vectores y calcular la distancia euclidiana entre ellos.\n","  dists_one = calculate_distances_one_loop(X_train_rand, X_val_rand)\n","  dists_two = calculate_distances_two_loops(X_train_rand, X_val_rand)\n","  difference = np.linalg.norm (dists_one - dists_two, ord = 'fro')\n","  if difference >= 1e-4:\n","    print(':( Las distancias no coinciden.')\n","    print(f'La diferencia entre las distancias es: {difference}')\n","    correct = False\n","    break\n","\n","if correct:\n","  print(':) Las distancias coinciden.')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5WCmEHsxIUl4"},"source":["#### (Opcional) Cálculo de distancias: Implementación usando solo vectorización\n","\n","Es posible calcular la distancia euclidiana sin la necesidad de usar bucles, gracias a las operaciones de vectorización que ofrece `python` es posible realizarlo de forma eficiente.\n","\n","Ahora implementemos una versión completamente vectorizada de la función de cálculo de distancia que no use ningún bucle."]},{"cell_type":"code","metadata":{"id":"kE2-JOdNHMYH"},"source":["def calculate_distances_no_loops(X_train, X_test):\n","  \"\"\"\n","    Calcule la distancia euclidiana al cuadrado entre cada elemento del\n","    conjunto de prueba y cada elemento del conjunto de entrenamiento.\n","\n","    distancia(x, y) = (x1 - y1)^2 + (x2 - y2)^2 + ... + (xd - yd)^2\n","\n","    Args / Return: Igual que los métodos previamente implementados\n","\n","    Note:\n","      - No puede usar bucles en esta implementación\n","      - Implementar el método usando solo numpy, no es válido usar métodos como\n","        np.norm u otros métodos ya implementados de scipy\n","  \"\"\"\n","  num_test = X_test.shape[0]\n","  num_train = X_train.shape[0]\n","\n","  # Inicializamos nuestra matriz de distancias\n","  dists = np.zeros((num_test, num_train))\n","\n","  # TODO: Calcule las distancias sin usar ningún bucle explícito.\n","  # Almacene el resultado en la posición dists[i, j].\n","  # HINT:\n","  # Intente formular la distancia euclidiana utilizando dos sumas con broadcast\n","  # y una multiplicación de matrices.\n","\n","\n","  # Retornamos las matriz de distancias\n","  return dists"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"689N1zyBKTgs"},"source":["Como lo realizado anteriormente, podemos verificar la correctitud de nuestra implementación comparando la versión completamente vectorizada con la versión de dos bucles original:"]},{"cell_type":"code","metadata":{"id":"SPQoFWs7KXwY"},"source":["# Test para probar la implementación de cálculo de distancias\n","\n","# Usado para controlar la aleatoriedad de los datos generados\n","np.random.seed(0)\n","\n","# Tamaños de los datos generados aleatoriamente\n","sizes = np.array([[10,2], [50, 5], [100, 10],[100,100], [200, 3]])\n","correct = True\n","\n","for size in sizes:\n","  X_train_rand = np.random.randn(*size).astype(np.float64)\n","  X_val_rand = np.random.randn(*size).astype(np.float64)\n","  dists_none = calculate_distances_no_loops(X_train_rand, X_val_rand)\n","  dists_two = calculate_distances_two_loops(X_train_rand, X_val_rand)\n","  difference = np.linalg.norm (dists_none - dists_two, ord = 'fro')\n","  if difference >= 1e-4:\n","    print(':( Las distancias no coinciden.')\n","    print(f'La diferencia entre las distancias es: {difference}')\n","    correct = False\n","    break\n","\n","if correct:\n","  print(':) Las distancias coinciden.')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PAEZwHQnL9tl"},"source":["Ahora podemos comparar la velocidad de nuestras tres implementaciones. Si ha implementado todo correctamente, la implementación completamente vectorizada debería ser la más eficiente, seguida por la implementación de un bucle. Sino llego a realizar la implementación de la versión completamente vectorizada, no tenga en cuenta su tiempo de ejecución en las siguientes pruebas (puede comentar esas porciones de código)."]},{"cell_type":"code","metadata":{"id":"s2w6Ql1LMQhg"},"source":["# Comparemos las velocidades de las implementaciones\n","def time_function(f, *args):\n","    \"\"\"\n","    Este método llama a la función f con argumentos (args) y\n","    retorna el tiempo (en segundos) que tomó ejecutarse\n","    \"\"\"\n","    import time\n","    tic = time.time()\n","    f(*args)\n","    toc = time.time()\n","    return toc - tic\n","\n","two_loop_time = time_function(calculate_distances_two_loops, X_train, X_val)\n","print('La versión con dos bucles tomó %f segundos' % two_loop_time)\n","\n","one_loop_time = time_function(calculate_distances_one_loop, X_train, X_val)\n","print('La versión con un bucle tomó %f segundos' % one_loop_time)\n","\n","no_loop_time = time_function(calculate_distances_no_loops, X_train, X_val)\n","print('La versión sin bucles tomó %f segundos' % no_loop_time)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rQxRFXmDMtLx"},"source":["Podemos observar que la versión con dos bubles es la más ineficiente, pero para pocos datos no hay mucha diferencia. Probemos ahora con una mayor cantidad de datos."]},{"cell_type":"code","metadata":{"id":"LKNhPI-iNEFs"},"source":["# Test para probar la eficiencia\n","\n","# Usado para controlar la aleatoriedad de los datos generados\n","np.random.seed(0)\n","\n","# Generamos datos aleatorios de dimensiones [1000x100]\n","X_train_rand = np.random.randn(1000, 100).astype(np.float64)\n","X_val_rand = np.random.randn(1000, 100).astype(np.float64)\n","\n","two_loop_time = time_function(calculate_distances_two_loops, X_train_rand, X_val_rand)\n","print('La versión con dos bucles tomó %f segundos' % two_loop_time)\n","\n","one_loop_time = time_function(calculate_distances_one_loop, X_train_rand, X_val_rand)\n","print('La versión con un bucle tomó %f segundos' % one_loop_time)\n","\n","no_loop_time = time_function(calculate_distances_no_loops, X_train_rand, X_val_rand)\n","print('La versión sin bucles tomó %f segundos' % no_loop_time)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rlpJbeqdNZgn"},"source":["Ahora si se ve una gran diferencia en la eficiencia de los diferentes tipos de implementación, siendo la mejor la versión sin bucles, seguida por la versión que usa un solo bucle.\n","\n","En conclusión, al momento de realizar implementaciones en `python` para Machine Learning, es muy recomendable tratar siempre de vectorizar sus operaciones y evitar bucles `for` o `while`. Tenga en cuenta que habrá casos donde no será posible vectorizar, por lo tanto se deberá realizar la implementación de forma tradicional."]},{"cell_type":"markdown","metadata":{"id":"0eDRrytMNChg"},"source":["## Implementación de 1-NN\n","\n","Empezaremos a implementar el clasificador en su versión más simple, es decir, haciendo uso del vecino más cercano ($k=1$). Para ello usaremos los métodos de distancias previamente implementados. Dadas estas distancias, para cada dato de prueba encontraremos al vecino más cercano y le asignaremos su clase (label).\n"]},{"cell_type":"markdown","metadata":{"id":"mTrBN_dnazpd"},"source":["### Predicción de etiquetas\n","\n","Tomar en consideración lo visto en clase, al momento de realizar las predicciones, no nos interesa la distancia mínima en si, lo que nos interesa es el índice del dato de entrenamiento mediante el cual obtuvimos la distancia mínima (`argmin`). Usando ese índice podemos acceder directamente a la clase real del dato de entrenamiento.\n","\n","Complete la siguiente función:"]},{"cell_type":"code","metadata":{"id":"X4BdcaSWNB7j"},"source":["def predict_labels_nearest_neighbor(dists, y_train):\n","  \"\"\"\n","  Dado una matriz de distancias entre los datos de prueba y entrenamiento,\n","  predecir la etiqueta para cada dato de prueba basándose solamente en el\n","  vecino más cercano\n","\n","    Args:\n","      - dists: matriz de dimensión (M x N), donde M es el número de datos de\n","               prueba y N es el número de datos de entrenamiento.\n","               dists[i, j] retorna la distancia entre el i-ésimo dato de prueba\n","               y el j-ésimo dato de entrenamiento.\n","      - y_train: arreglo de dimensión (N), donde N es el número de datos de\n","                entrenamiento. Este arreglo contiene las clases (labels) reales.\n","\n","    Returns:\n","      - y_pred: arreglo de dimensión (M,) conteniendo las etiquetas predichas\n","                para cada dato de prueba, donde y_pred[i] es la etiqueta predicha\n","                para el i-ésimo ejemplo de prueba.\n","                Cada etiqueta debe ser un número entero en el rango [0, num_classes-1].\n","\n","    Note:\n","      - Es válido usar bucles para iterar sobre la data de prueba\n","      - Es válido usar métodos como np.min, np.argmin\n","  \"\"\"\n","  num_test = dists.shape[0]\n","\n","  # Inicializamos nuestro arreglo de predicciones\n","  y_pred = np.zeros(num_test)\n","\n","  # TODO: Use la matriz de distancias para encontrar al vecino más cercano\n","  # del i-ésimo dato de prueba, y use y_train para encontrar las etiquetas\n","  # de estos vecinos.\n","\n","\n","  # Retornamos el arreglo con las etiquetas predichas\n","  return y_pred"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8b1P_Dp7eIm4"},"source":["### Encapsulación en clases\n","\n","Habiendo implementado toda la funcionalidad requerida para el clasificador basado en el vecino más cercano ($k=1$). Podemos definir una clase simple para encapsular toda la funcionalidad:"]},{"cell_type":"code","metadata":{"id":"WPcFDcM_b-Ej"},"source":["class NearestNeighbor:\n","\n","  def __init__(self, num_loops=0):\n","    \"\"\"\n","    Este método inicializa los hiperparámetros de nuestro clasificador\n","\n","    Args:\n","      - num_loops: Determina que implementación usar para calcular las distancias\n","                  entre datos de entrenamiento y de prueba.\n","    \"\"\"\n","    self.n_neighbors = 1\n","    self.num_loops = num_loops\n","\n","  def fit(self, X_train, y_train):\n","    \"\"\"\n","    Este método entrena el modelo usando la data de entrenamiento y sus etiquetas.\n","\n","    Args:\n","      - X_train: data de entrenamiento de dimensión (N x D), donde N es el\n","                 número de muestras y D es el número de características.\n","      - y_train: arreglo de dimensión (N), donde N es el número de muestras.\n","                 Este arreglo contiene las etiquetas (clases) de la data.\n","\n","    Note:\n","      - Recuerde que el clasificador memoriza la data de entrenamiento.\n","    \"\"\"\n","    self.X_train = X_train\n","    self.y_train = y_train\n","\n","  def predict(self, X_test):\n","    \"\"\"\n","    Este método predice clases (labels) para la data de prueba\n","\n","    Args:\n","      - X_test: data de prueba de dimensión (M x D), donde M es el\n","                número de muestras y D es el número de características.\n","\n","    Returns:\n","      - y_test_pred: arreglo de dimensión (M,) conteniendo las etiquetas predichas\n","                     para cada dato de prueba, donde y_test_pred[i] es la etiqueta predicha\n","                     para el dato X_test[i].\n","    \"\"\"\n","    if self.num_loops == 0:\n","      dists = calculate_distances_no_loops(self.X_train, X_test)\n","    elif self.num_loops == 1:\n","      dists = calculate_distances_one_loop(self.X_train, X_test)\n","    elif self.num_loops == 2:\n","      dists = calculate_distances_two_loops(self.X_train, X_test)\n","    else:\n","      raise ValueError('Valor inválido %d para num_loops' % self.num_loops)\n","    return predict_labels_nearest_neighbor(dists, self.y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XCqHrNVToDA4"},"source":["Tomar en consideración esta implementación ya que usted implementará los métodos de k-NN."]},{"cell_type":"markdown","metadata":{"id":"WSUT3cDMoQqj"},"source":["### Límites de Decisión\n","\n","Como lo explicado en clase, en problemas de clasificación podemos particionar el espacio en regiones de decisión donde cada región es una clase. A continuación, mostraremos los límites de decisión basándonos en el vecino más cercano. Podrá visualizar la separabilidad de las clases si las implementaciones anteriores fueron llevadas a cabo de forma correcta."]},{"cell_type":"code","metadata":{"id":"PCqex6YCo9Zk"},"source":["def plot_decision_boundary(X_train, y_train, clf, name='NN', use_figure=True):\n","  \"\"\"\n","     Este método permite visualizar nuestros datos de entrenamiento y prueba dado\n","     un modelo de clasificación que denotamos por 'clf'. El clasificador debe tener\n","     implementados los métodos .fit y .predict.\n","  \"\"\"\n","  # Realizamos la fase de entrenamiento\n","  clf.fit(X_train, y_train)\n","\n","  # Calculamos los límites de la malla a visualizar\n","  x_min, x_max = X_train[:, 0].min() - 1, X_train[:, 0].max() + 1\n","  y_min, y_max = X_train[:, 1].min() - 1, X_train[:, 1].max() + 1\n","\n","  h = .01\n","  xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n","                      np.arange(y_min, y_max, h))\n","\n","  # Para visualizar el límite de decisión, necesitaremos asignar un color\n","  # a cada punto en malla [x_min, x_max] x [y_min, y_max].\n","  Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n","\n","  # Colocamos el resultado en un diagrama de color\n","  Z = Z.reshape(xx.shape)\n","  if use_figure:\n","    plt.figure()\n","  plt.pcolormesh(xx, yy, Z, cmap=cmap_light, alpha=.8)\n","\n","  # Visualizamos los datos de entrenamiento y validación\n","  plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cmap_bold, edgecolor='k', s=20)\n","  plt.xlim(xx.min(), xx.max())\n","  plt.ylim(yy.min(), yy.max())\n","  name = str(clf.n_neighbors) + '-' + name\n","  plt.title(\"{} (k = {})\".format(name, clf.n_neighbors))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zyQZvHLQqBzR"},"source":["# Creamos una instancia de la clase implementada\n","clf = NearestNeighbor()\n","\n","# Visualizamos los límites de decisión\n","plot_decision_boundary(X_train_new, y_train, clf)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"13-XZYdRzNRZ"},"source":["Como podemos observar, el límite de decisión separa correctamente ambas clases. Visualmente podemos determinar si el clasificador fue bueno o no. Sin embargo, para generar esta visualización, fue necesario ejecutar el clasificador para cada punto y asignarle un color. Necesitamos otra forma de evaluar el rendimiento de nuestro modelo."]},{"cell_type":"markdown","metadata":{"id":"3QgBet1KmCPP"},"source":["### Métrica de Evaluación\n","\n","Una forma de evaluar el rendimiento de nuestro modelo es mediante métricas de evaluación. Existen diferentes métricas para clasificación, regresión, clustering, etc. Para este ejemplo haremos uso del `accuracy`, el cual está definido de la siguiente manera:\n","\n","$$\\text{Accuracy} = \\frac{\\text{Número de predicciones correctas}}{\\text{Número total de predicciones}}$$\n"]},{"cell_type":"code","metadata":{"id":"CbKzjErPmCmn"},"source":["def accuracy(y_true, y_pred):\n","  \"\"\"\n","    Este método devuelve la métrica de evaluación 'accuracy' del clasificador.\n","    Recordar que accuracy cuenta la cantidad promedio de datos correctamente predichos\n","    para ello comparamos los valores reales, 'y_true', con los valores predichos,\n","    'y_pred', realizamos el conteo de valores correctamente clasificados y retornamos\n","    el promedio.\n","\n","    Args:\n","        - y_true: arreglo de dimensión (M,) conteniendo las etiquetas reales\n","        - y_pred: arreglo de dimensión (M,) conteniendo las etiquetas predichas\n","\n","    Returns:\n","        - accuracy: Accuracy del clasificador. Su valor estará en el rango de [0, 1],\n","                    siendo 1 una clasificación perfecta.\n","    Note:\n","        - Puede hacer uso de métodos como np.mean()\n","  \"\"\"\n","  # TODO: Calcule el accuracy\n","\n","  return\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XvQMbUW21GQ0"},"source":["### Evaluación del Modelo\n","\n","Realizaremos la evaluación de nuestro modelo haciendo uso de la métrica previamente implementada.\n"]},{"cell_type":"code","metadata":{"id":"w9Sdz8jw1R2J"},"source":["# TODO: Calcule el accuracy de la data de entrenamiento y la data de validación\n","# Utilice la clase NearestNeighbor previamente implementada\n","\n","# Creamos una instancia del clasificador implementado\n","clf =\n","\n","# Entrenamos el modelo usando la data de entrenamiento\n","# Recuerde que es necesario usar la data estandarizada\n","clf.\n","\n","# Predecimos etiquetas para la data de entrenamiento\n","# Recuerde que es necesario usar la data estandarizada\n","y_train_pred =\n","\n","# Calculamos el accuracy de la data de entrenamiento\n","acc_train =\n","\n","# Predecimos etiquetas para la data de validación\n","# Recuerde que es necesario usar la data estandarizada\n","y_val_pred =\n","\n","# Calculamos el accuracy de la data de validación\n","acc_val =\n","\n","# Imprimimos los resultados\n","print(f'Accuracy de la data de entrenamiento: {acc_train}.')\n","print(f'Accuracy de la data de validación: {acc_val}.')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"594S5TlZ2_Sg"},"source":["De acuerdo a los resultados, podemos observar que la data de entrenamiento obtuvo un accuracy perfecto y la data de validación muestra un valor cercano. Ya que en este ejemplo estamos haciendo uso de datos simples, la separabilidad de las clases es bastante obvia. Sin embargo, la data del mundo real es mucho más compleja. Cuando implementemos los $k$ vecinos más cercanos, mostraremos la diferencia entre ambas predicciones en data un poco más compleja."]},{"cell_type":"markdown","metadata":{"id":"3mklVd8V3-Uv"},"source":["### Error de clasificación\n","\n","Recordemos que en clase mencionamos el error de clasificación. Este error cuenta la cantidad de datos mal clasificados, el error se puede calcular a partir del accuracy simplemente restando a $1$ el valor del accuracy. Es decir:\n","\n","$$\\text{Error} = \\frac{\\text{Número de predicciones incorrectas}}{\\text{Número total de predicciones}} = 1 - \\text{Accuracy}$$\n","\n","En otros modelos, el error estará definido como una función de pérdida."]},{"cell_type":"code","metadata":{"id":"5y14--kD5Bof"},"source":["print(f'Error de la data de entrenamiento: {1. - acc_train}.')\n","print(f'Error de la data de validación: {1. - acc_val}.')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H7QSAkI75cdV"},"source":["## Implementación de KNN\n","\n","Habiendo concluído con la implementación del vecino más cercano ($k=1$), procederemos a generalizar la implementación para considerar $k$ vecinos. Del mismo modo que hicimos en el vecino más cercano, usaremos los métodos de distancias previamente implementados. Dadas estas distancias, para cada dato de prueba encontraremos los $k$ vecinos más cercanos y asignaremos la clase (label) basándonos en el voto mayoritario (moda)."]},{"cell_type":"markdown","metadata":{"id":"b2dxUr_t7jzA"},"source":["### Predicción de etiquetas\n","\n","Tomar en consideración lo visto en clase, al momento de realizar las predicciones, no nos interesa la distancia mínima en si, lo que nos interesa son los índices del datos de entrenamiento más cercanos. Usando este vector de índices podemos acceder directamente a las clases reales de los datos de entrenamiento y hacer el conteo de etiquetas para determinar la clase predicha para cada dato de prueba."]},{"cell_type":"code","metadata":{"id":"7ilDDHWaBqAo"},"source":["def predict_labels(dists, y_train, k=1):\n","  \"\"\"\n","    Dado una matriz de distancias entre datos de prueba y entrenamiento, predecir\n","    la etiqueta para cada dato de prueba considerando el voto mayoritario entre\n","    sus k vecinos más cercanos en el conjunto de entrenamiento.\n","\n","    En caso de empate, esta función deberá devolver la etiqueta más pequeña.\n","    Por ejemplo, si k = 5 y los 5 vecinos más cercanos a un ejemplo de prueba\n","    tienen etiquetas [1, 2, 1, 2, 3], entonces hay un empate entre 1 y 2 (cada\n","    uno tiene 2 votos), por lo tanto debemos devolver 1 ya que es la etiqueta más\n","    pequeña.\n","\n","    Args:\n","      - dists: matriz de dimensión (M x N), donde M es el número de datos de\n","               prueba y N es el número de datos de entrenamiento, donde\n","               dists[i, j] retorna la distancia entre el i-ésimo dato de prueba\n","               y el j-ésimo dato de entrenamiento.\n","      - y_train: arreglo de dimensión (N), donde N es el número de datos de\n","                 entrenamiento. Este arreglo contiene las clases (labels) reales.\n","      - k: número de vecinos más cercanos a utilizar en la clasificación.\n","\n","    Returns:\n","      - y_pred: arreglo de dimensión (M,) conteniendo las etiquetas predichas\n","                para cada dato de prueba, donde y_pred[i] es la etiqueta predicha\n","                para el i-ésimo ejemplo de prueba.\n","                Cada etiqueta debe ser un número entero en el rango [0, num_classes-1].\n","\n","    Note:\n","      - Es válido usar bucles para iterar sobre la data de prueba\n","      - Es válido usar métodos como np.argmax, np.argsort, np.bincount, etc.\n","  \"\"\"\n","  num_test = dists.shape[0]\n","\n","  # Inicializamos nuestro arreglo de predicciones\n","  y_pred = np.zeros(num_test)\n","\n","  # Iteramos sobre cada dato de prueba para realizar su predicción respectiva\n","  for i in range(num_test):\n","    # TODO: Use la matriz de distancias para encontrar los k vecinos más cercanos\n","    # del i-ésimo dato de prueba, y use y_train para encontrar las etiquetas\n","    # de estos vecinos. Almacene estas etiquetas en el arreglo closest_y.\n","    # HINT: Revisar la función np.argsort\n","    closest_y =\n","\n","    # Ahora que ha encontrado las etiquetas de los k vecinos más cercanos,\n","    # necesita encontrar la etiqueta más común en el arreglo de etiquetas closest_y.\n","    # Almacene esta etiqueta en y_pred[i].\n","    # Rompa empates eligiendo la etiqueta más pequeña.\n","    y_pred[i] =\n","\n","  # Retornamos el arreglo con las etiquetas predichas\n","  return y_pred\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mYaD8SOnCG5f"},"source":["### Encapsulación en clases\n","\n","Habiendo implementado toda la funcionalidad requerida para el clasificador basado en los $k$ vecinos más cercanos. Podemos definir una clase simple para encapsular toda la funcionalidad:"]},{"cell_type":"code","metadata":{"id":"vSQ_oLMmCaD-"},"source":["class KNearestNeighbor:\n","\n","  def __init__(self, n_neighbors=1, num_loops=0):\n","    \"\"\"\n","      Este método inicializa los hiperparámetros de nuestro clasificador\n","\n","      Args:\n","        - n_neighbors: Número de vecinos a utilizar en las predicciones\n","        - num_loops: Determina que implementación usar para calcular las distancias\n","                    entre datos de entrenamiento y e prueba.\n","    \"\"\"\n","    self.n_neighbors = n_neighbors\n","    self.num_loops = num_loops\n","\n","  def fit(self, X_train, y_train):\n","    \"\"\"\n","      Este método entrena el modelo usando la data de entrenamiento y sus etiquetas.\n","\n","      Args:\n","        - X_train: data de entrenamiento de dimensión (N x D), donde N es el\n","                  número de muestras y D es el número de características.\n","        - y_train: arreglo de dimensión (N), donde N es el número de muestras.\n","                  Este arreglo contiene las etiquetas (clases) de la data.\n","\n","      Note:\n","        - Recuerde que el clasificador memoriza la data de entrenamiento.\n","    \"\"\"\n","    #TODO: Implemente la funcionalidad de este método\n","\n","\n","  def predict(self, X_test):\n","    \"\"\"\n","      Este método predice clases (labels) para la data de prueba\n","\n","      Args:\n","        - X_test: data de prueba de dimensión (M x D), donde M es el\n","                  número de muestras y D es el número de características.\n","      Returns:\n","        - y_test_pred: arreglo de dimensión (M,) conteniendo las etiquetas predichas\n","                      para cada dato de prueba, donde y_test_pred[i] es la etiqueta predicha\n","                      para el dato X_test[i].\n","    \"\"\"\n","    # TODO: Implemente la funcionalidad de este método\n","\n","    return"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FLQPAwjeEoRu"},"source":["Para probar su implementación, puede hacer uso de la implementación del vecino más cercano y comparar los resultados con un $k=1$."]},{"cell_type":"code","metadata":{"id":"rflM1UgQEwXJ"},"source":["# Test del vecino más cercano y k-NN con k=1\n","\n","# Creamos una instancia de la clase NearestNeighbor y entrenamos el modelo\n","nn = NearestNeighbor()\n","nn.fit(X_train_new, y_train)\n","\n","# Creamos una instancia de la clase KNearestNeighbor con k=1\n","knn = KNearestNeighbor(n_neighbors=1)\n","knn.fit(X_train_new, y_train)\n","\n","# Realizamos predicciones para la data de validación usando ambas implementaciones\n","y_val_pred_nn = nn.predict(X_val_new)\n","y_val_pred_knn = knn.predict(X_val_new)\n","\n","# Realizamos la comparación\n","difference = (y_val_pred_nn != y_val_pred_knn).sum()\n","if difference != 0:\n","  print(':( Su implementación de 1-NN no fue realizada correctamente.')\n","  print(f'Sus predicciones difieren en {difference} muestras.')\n","else:\n","  print(':) Su implementación de 1-NN fue realizada correctamente.')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LIR41OV7GpCe"},"source":["Puede adicionar más casos de prueba para diferentes valores de $k$ y verificar si su implementación fue realizada correctamente."]},{"cell_type":"markdown","metadata":{"id":"gOlWtl0uEBxV"},"source":["### Límites de Decisión\n","\n","Del mismo modo que hicimos en el vecino más cercano. Podemos visualizar los límites de decisión, haciendo uso de los $k$ vecinos más cercanos. Para ello, mostraremos los límites de decisión para $k=1$, $k=5$ y $k=$número de muestras."]},{"cell_type":"code","metadata":{"id":"KV8Zx36DInd3"},"source":["plt.subplots(figsize =(18, 5))\n","\n","plt.subplot(1, 3, 1)\n","# Creamos una instancia de la clase implementada\n","clf = KNearestNeighbor(n_neighbors=1)\n","plot_decision_boundary(X_train_new, y_train, clf, use_figure=False)\n","\n","plt.subplot(1, 3, 2)\n","# Creamos una instancia de la clase implementada\n","clf = KNearestNeighbor(n_neighbors=5)\n","plot_decision_boundary(X_train_new, y_train, clf, use_figure=False)\n","\n","plt.subplot(1, 3, 3)\n","# Creamos una instancia de la clase implementada\n","clf = KNearestNeighbor(n_neighbors=X_train_new.shape[0])\n","plot_decision_boundary(X_train_new, y_train, clf, use_figure=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YIgyOxguKTRC"},"source":["Podemos visualizar que para un $k$ igual al número de muestras, caemos en underfitting, el modelo es demasiado simple que clasifica basándose en la clase mayoritaria del número total de muestras."]},{"cell_type":"markdown","metadata":{"id":"QgAaqhcgLBJp"},"source":["## Clasificación Multiclase\n","\n","Para mostrar la importancia de KNN, generaremos distribuciones de datos más complejos y con más clases."]},{"cell_type":"code","metadata":{"id":"71SJsbB2LTA0"},"source":["# Definimos mapas de color\n","cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF', '#AFAFAF', '#fafa30'])\n","cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF', '#AFAFAF', '#fafa30'])\n","\n","# Generamos datos aleatorios\n","X, y = make_blobs(400, 2, centers=5, random_state=10, cluster_std = 2.5)\n","\n","# visualizamos la data generada\n","plt.figure(figsize=(7,6))\n","plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap=cmap_bold)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GxefWtfaM1lP"},"source":["Podemos observar que la data ahora es un poco más compleja que la anterior y con más clases. Usaremos esta data para evaluar nuestro modelo de $k$-NN. Por lo tanto, usted realizará la implementación de todos los pasos desde preprocesamiento hasta clasificación, usando los métodos que ya implementados."]},{"cell_type":"markdown","metadata":{"id":"pKPWJgmENzIs"},"source":["#### Particionamiento de Datos\n","\n","Particione el conjunto de datos en entrenamiento, validación y prueba. Considerar un particionamiento de $60\\%$ para entrenamiento, $20\\%$ para validación y $20\\%$ para prueba. Para ello es necesario usar el método antes implementado (`train_test_split`)."]},{"cell_type":"code","metadata":{"id":"9at_WGr8OXU1"},"source":["# TODO: Realice los particionamientos de forma similar a lo implementado anteriormente\n","# Particionamos el conjunto de datos en 80% de entrenamiento y 20% de prueba\n","_X_train, _y_train, X_test, y_test =\n","\n","# Particionamos el conjunto de datos de entrenamiento en 75% de entrenamiento y 20% de prueba\n","X_train, y_train, X_val, y_val =\n","\n","# Imprimimos los tamaños de cada particionamiento\n","print('Tamaño original del dataset: ', X.shape)\n","print('---------------------------')\n","print('Tamaño de la data de entrenamiento: ', X_train.shape)\n","print('Tamaño de la data de validación: ', X_val.shape)\n","print('Tamaño de la data de prueba: ', X_test.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g8QZ5oCMO2AP"},"source":["#### Visualización del conjunto de datos\n","\n","Procederemos con la visualización de los particionamientos previamente realizados. En este paso solo mostraremos la data de entrenamiento y de validación para saber el tipo de clasificación que necesitamos realizar. La data de test solo la tocaremos al final."]},{"cell_type":"code","metadata":{"id":"bxwHDVKTPEmy"},"source":["plot_dataset(X_train, y_train, X_val, y_val)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HYOPWteOPJMD"},"source":["#### Estandarización de la data\n","\n","Estandarizamos la data de entrenamiento y validación, recordar que para estandarizar la data de validación, hacemos uso de las estadísticas calculadas en la data de entrenamiento."]},{"cell_type":"code","metadata":{"id":"lKsMNXO6Pi9P"},"source":["#TODO: Estandarice la data de entrenamiento y validación de forma similar a lo\n","# implementado anteriormente\n","\n","# Estandarizar la data de entrenamiento (X_train) y calcular la media y desviación estándar\n","X_train_new, X_train_mu, X_train_std =\n","\n","# Estandarizar la data de validación (X_val) haciendo uso de las estadísticas\n","# calculadas en la data de entrenamiento\n","X_val_new ="],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6CpF_lSHQAoP"},"source":["Visualicemos los datos estandarizados:"]},{"cell_type":"code","metadata":{"id":"UzSdg7jaQCq5"},"source":["plot_dataset(X_train_new, y_train, X_val_new, y_val)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ag45NX5LQLX5"},"source":["#### Límites de Decisión\n","\n","Visualizaremos los límites de decisión para este conjunto de datos, haciendo uso de los $k$ vecinos más cercanos. Para ello, mostraremos los límites de decisión para $k=1$, $k=5$ y $k=$número de muestras."]},{"cell_type":"code","metadata":{"id":"bmExLwmLQeoi"},"source":["plt.subplots(figsize =(18, 5))\n","\n","plt.subplot(1, 3, 1)\n","# Creamos una instancia de la clase implementada\n","clf = KNearestNeighbor(n_neighbors=1)\n","plot_decision_boundary(X_train_new, y_train, clf, use_figure=False)\n","\n","plt.subplot(1, 3, 2)\n","# Creamos una instancia de la clase implementada\n","clf = KNearestNeighbor(n_neighbors=5)\n","plot_decision_boundary(X_train_new, y_train, clf, use_figure=False)\n","\n","plt.subplot(1, 3, 3)\n","# Creamos una instancia de la clase implementada\n","clf = KNearestNeighbor(n_neighbors=X_train_new.shape[0])\n","plot_decision_boundary(X_train_new, y_train, clf, use_figure=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HTIG0uTtQqnI"},"source":["Como podemos observar, para un $k=1$, el modelo se sobreajusta a los datos de entrenamiento (overfitting), para un $k=5$, tenemos un ajuste adecuado y, para un $k=$número de muestras, tenemos un modelo demasiado simple (underfitting)."]}]}